{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: abaglione and lihuacai\n",
    "\n",
    "Credit to Tyler Spears and Sonia Baee, who developed the precursor\n",
    "to this preprocessing script\n",
    "\"\"\"\n",
    "\n",
    "# imports\n",
    "import sys\n",
    "import os\n",
    "import functools\n",
    "import pathlib\n",
    "import glob\n",
    "import collections\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ModuleNotFoundError:\n",
    "    import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import pipeline\n",
    "\n",
    "from sklearn import impute\n",
    "from sklearn import datasets\n",
    "from sklearn import svm, linear_model, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.autolayout': True})\n",
    "plt.rcParams.update({'figure.facecolor': [1.0, 1.0, 1.0, 1.0]})\n",
    "\n",
    "# configure autoreloading of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the weekly feature vectors \n",
    "wkly_df = pd.read_csv('features/all_ind_wkly.csv')\n",
    "\n",
    "# Store the feature names\n",
    "featnames = list(wkly_df.columns)\n",
    "\n",
    "wkly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing missing survey data -- weekly data\n",
    "impfeats = ['cope_alcohol_tob', 'physical_pain', 'connected', 'receive_support', 'anx',\n",
    "            'dep', 'active', 'support_others', 'healthy_food']\n",
    "featnames_app = [i for i in featnames if i not in impfeats]\n",
    "feats_app = wkly_df.drop(axis=1, columns=impfeats)\n",
    "feats_napp = wkly_df[impfeats].copy()\n",
    "pipeline.fillmissing(feats_napp, impfeats, -1, np.nan)\n",
    "\n",
    "# I think Lee was imputing the app features and survey features separately...hmm\n",
    "imputer = IterativeImputer(max_iter=50, random_state=1008, add_indicator=True)\n",
    "imputer.fit(feats_napp)\n",
    "impfeats_ind = [i+'_ind' for i in impfeats]\n",
    "impfeats_c = copy.deepcopy(impfeats)\n",
    "impfeats_c.extend(impfeats_ind)\n",
    "feats_napp = pd.DataFrame(\n",
    "    np.round(imputer.transform(feats_napp)), columns=impfeats_c)\n",
    "all_feats = pd.concat([feats_app, feats_napp], copy=True, axis=1)\n",
    "all_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_feats = [n for n in featnames if 'frequency' in n]\n",
    "reg_feats = [n for n in featnames if 'daysofuse' in n]\n",
    "dur_feats = [n for n in featnames if 'duration' in n and 'betweenlaunch' not in n]\n",
    "lau_dur_feats = [n for n in featnames if 'betweenlaunch' in n]\n",
    "\n",
    "# Correction for missing data (change from -1 to 0 for some features)\n",
    "pipeline.fillmissing(all_feats, frequency_feats, -1, 0)\n",
    "pipeline.fillmissing(all_feats, reg_feats, -1, 0)\n",
    "pipeline.fillmissing(all_feats, dur_feats, -1, 0)\n",
    "pipeline.fillmissing(all_feats, lau_dur_feats, -1, 3600*24*7)\n",
    "\n",
    "#add the intercept columns for the linear mixed model\n",
    "all_feats['intercept'] = 1\n",
    "\n",
    "#outcomes transformation -- anx, dep\n",
    "#week to week change as outcome\n",
    "#change to baseline level as outcome\n",
    "#instead of difference, consider ratio between the weekly value and the baseline\n",
    "#global average being subtracted\n",
    "\n",
    "all_feats['anx'].hist()\n",
    "all_feats['dep'].hist()\n",
    "\n",
    "#add classification outcomes\n",
    "all_feats['dep_cat'] = np.where(all_feats['dep'] >= 4, 1, 0)\n",
    "all_feats['anx_cat'] = np.where(all_feats['anx'] >= 3, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Feature Set Spec -----------\n",
    "\n",
    "APPS = ['aspire', 'boostme', 'dailyfeats', 'icope', 'mantra', 'messages',\n",
    "        'moveme', 'relax', 'slumbertime', 'thoughtchallenger', 'worryknot']\n",
    "ENGAGEMENT_METRICS = ['frequency', 'duration',\n",
    "                      'betweenlaunch_duration', 'days_of_use']\n",
    "TIMES_OF_DAY = ['morning', 'afternoon', 'evening', 'late_night']\n",
    "\n",
    "# Survey Features Only\n",
    "survey_fs_cols = ['cope_alcohol_tob', 'physical_pain', 'connected', 'receive_support', 'active',\n",
    "                  'support_others', 'healthy_food', 'cope_alcohol_tob_ind', 'physical_pain_ind',\n",
    "                  'connected_ind', 'receive_support_ind', 'active_ind', 'support_others_ind',\n",
    "                  'healthy_food_ind']\n",
    "\n",
    "# App Features - All Apps\n",
    "app_overall_fs_cols = ['weekofstudy', 'frequency', 'daysofuse', 'duration', 'duration_mean',\n",
    "                       'duration_std', 'duration_min', 'duration_max', 'betweenlaunch_duration_mean',\n",
    "                       'betweenlaunch_duration_std', 'num_apps_used']\n",
    "\n",
    "# App Features - Individual Apps\n",
    "app_ind_fs_cols = ['weekofstudy'] + \\\n",
    "    [col for col in all_feats.columns\n",
    "     if any([app in col for app in APPS])\n",
    "     and any([metric in col for metric in ENGAGEMENT_METRICS])\n",
    "     and not any([tod in col for tod in TIMES_OF_DAY])]\n",
    "\n",
    "app_ind_fs_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one last feature - an indicator of which app was used most often\n",
    "df = all_feats[[i for i in app_ind_fs_cols if 'frequency' in i]].copy()\n",
    "all_feats['most_used_app'] = [i[1] for i in df.idxmax(axis=1).str.split('_')]\n",
    "\n",
    "#dummitize the most_used_app column\n",
    "mua_dummy_df = pd.get_dummies(all_feats['most_used_app'])\n",
    "mua_dummy_cols = ['most_used_app_' + c for c in mua_dummy_df.columns]\n",
    "all_feats = pd.concat([all_feats,mua_dummy_df],axis=1)\n",
    "\n",
    "# Create a subset with survey features + only features from the most used app\n",
    "mua_dfs = []\n",
    "\n",
    "def rename_mapper(colname):\n",
    "    new_colname = colname.replace('_'+all_feats['most_used_app'][i], '')\n",
    "    return(new_colname)\n",
    "\n",
    "for i in range(all_feats.shape[0]):\n",
    "    df = all_feats[[\n",
    "        e for e in app_ind_fs_cols if all_feats['most_used_app'][i] in e]].iloc[[i]].copy()\n",
    "    df.rename(mapper=rename_mapper, axis=1, inplace=True)\n",
    "    mua_dfs.append(df)\n",
    "\n",
    "app_mua_feats = pd.concat(mua_dfs, sort=False)\n",
    "survey_app_mua_feats = pd.concat(\n",
    "    [all_feats[['pid', 'weekofstudy', 'anx', 'dep','anx_cat', 'dep_cat', 'most_used_app']],\n",
    "     all_feats[survey_fs_cols],\n",
    "     app_mua_feats], \n",
    "    axis=1, copy=True\n",
    ")\n",
    "\n",
    "survey_app_mua_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create last featureset\n",
    "# App Features - Only Features from the Most Used App for a Given Observation (Row)\n",
    "app_mua_fs_cols = ['weekofstudy', 'frequency', 'daysofuse', \n",
    "                   'duration', 'duration_mean', 'duration_std',\n",
    "                   'duration_min', 'duration_max', 'betweenlaunch_duration_mean', \n",
    "                   'betweenlaunch_duration_std']\n",
    "\n",
    "# Add new dummy columns to other featuresets\n",
    "app_overall_fs_cols += mua_dummy_cols\n",
    "app_ind_fs_cols += mua_dummy_cols\n",
    "\n",
    "app_ind_fs_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of featuresets\n",
    "featuresets = {\n",
    "    'survey_fs': survey_fs_cols,\n",
    "    'app_overall_fs': app_overall_fs_cols,\n",
    "    'app_ind_fs': app_ind_fs_cols,\n",
    "    'app_mua_fs': app_mua_fs_cols,\n",
    "    'survey_app_overall_fs': survey_fs_cols+app_overall_fs_cols, \n",
    "    'survey_app_ind_fs': survey_fs_cols+app_ind_fs_cols,\n",
    "    'survey_app_mua_fs': survey_fs_cols+app_mua_fs_cols\n",
    "}\n",
    "featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######regression tasks on 1-5 scale (cut off on both 1 (floor) and 5 (ceiling)) using lasso linear mixed effect model;\n",
    "alpha_list = np.arange(0.1, 0.81, 0.1)\n",
    "lmm_res = []\n",
    "\n",
    "for alpha in alpha_list:\n",
    "    print('alpha: {0}'.format(alpha))\n",
    "    for fs_name, fs_cols in featuresets.items():\n",
    "        if 'mua' in fs_name:\n",
    "            df = survey_app_mua_feats\n",
    "        else:\n",
    "            df = all_feats\n",
    "        \n",
    "        df[['intercept'] + fs_cols].to_csv('features/%s.csv' % fs_name)\n",
    "        for target in ['anx', 'dep']:\n",
    "            res = pipeline.genMixedLM(df, target, ['intercept'] + fs_cols,\n",
    "                            'pid', fs_name, alpha=alpha)\n",
    "            lmm_res.append(res.copy())\n",
    "\n",
    "lmm_res = pd.concat(lmm_res, copy=True, ignore_index=True, sort=False)\n",
    "lmm_res.to_csv('results/lmm_res.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "id_col = 'pid'\n",
    "target_cols = ['anx_cat', 'dep_cat']\n",
    "\n",
    "for fs_name, fs_cols in featuresets.items():\n",
    "\n",
    "    if 'mua' not in fs_name:\n",
    "        df = all_feats\n",
    "    else:\n",
    "        # Handle special cases in which we want data only from the most used app\n",
    "        df = survey_app_mua_feats\n",
    "\n",
    "    X = df[[id_col] + fs_cols].copy()\n",
    "    \n",
    "    ''' If this is a featureset with app features \n",
    "        Get a list of one-hot-encoded columns from the most_used_app feature.'''\n",
    "    mua_onehots = [col for col in X.columns if 'most_used_app' in col]\n",
    "    \n",
    "    print(X.columns)\n",
    "    # Get categorical feature indices - will be used with SMOTENC later\n",
    "    nominal_idx = sorted([X.columns.get_loc(c) for c in ['pid'] + mua_onehots])\n",
    "\n",
    "    # y\n",
    "    targets = {\n",
    "        'anxiety': df['anx_cat'].copy(),\n",
    "        'depression': df['dep_cat'].copy()\n",
    "    }\n",
    "\n",
    "    for target_name, target_col in targets.items():\n",
    "        for method in ['RF', 'XGB']:\n",
    "            res = pipeline.classifyMood(X=X, y=target_col, id=id_col, target=target_name,\n",
    "                              nominal_idx = nominal_idx, fs=fs_name, method=method)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "int-eng",
   "language": "python",
   "name": "int-eng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
